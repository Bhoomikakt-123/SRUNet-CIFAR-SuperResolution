from nbformat import v4 as nbf
import os

# Create a list of notebook cells
cells = []

# Markdown Title and Description
cells.append(nbf.new_markdown_cell("# ðŸ§  SRUNet-CIFAR: Super-Resolution Using CNN\n\nThis notebook implements a deep learning-based image super-resolution model (SRUNet) using PyTorch. It upscales low-resolution CIFAR-10 images (32Ã—32) into high-resolution (128Ã—128) images using a custom CNN architecture. Evaluation is done using PSNR and SSIM metrics."))

# Code cells (step-by-step)
cells.append(nbf.new_code_cell("""import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision import datasets
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as ssim
import numpy as np
from PIL import Image"""))

cells.append(nbf.new_code_cell("""device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)"""))

cells.append(nbf.new_code_cell("""transform_input = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

transform_target = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])"""))

cells.append(nbf.new_code_cell("""trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_input)
testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_input)

train_loader = DataLoader(trainset, batch_size=8, shuffle=True)
test_loader = DataLoader(testset, batch_size=8, shuffle=False)"""))

cells.append(nbf.new_code_cell("""class SRUNet(nn.Module):
    def __init__(self):
        super(SRUNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1)
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x"""))

cells.append(nbf.new_code_cell("""model = SRUNet().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for data, _ in train_loader:
        input_images = data.to(device)

        target_images = torch.stack([
            transform_target(transforms.ToPILImage()(img.cpu()))
            for img in input_images
        ]).to(device)

        output_images = model(input_images)
        output_resized = nn.functional.interpolate(output_images, size=(128, 128), mode='bilinear', align_corners=False)

        loss = criterion(output_resized, target_images)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}")"""))

cells.append(nbf.new_code_cell("""torch.save(model.state_dict(), "srunet_model.pth")
print("Model saved as srunet_model.pth")"""))

cells.append(nbf.new_code_cell("""def calculate_psnr(target, output):
    mse = np.mean((target - output) ** 2)
    if mse == 0:
        return 100
    PIXEL_MAX = 1.0
    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))

def calculate_ssim(target, output):
    return ssim(target, output, channel_axis=-1)"""))

cells.append(nbf.new_code_cell("""model.eval()
psnr_values, ssim_values = [], []

with torch.no_grad():
    for data, _ in test_loader:
        input_images = data.to(device)
        target_images = torch.stack([
            transform_target(transforms.ToPILImage()(img.cpu()))
            for img in input_images
        ]).to(device)

        output_images = model(input_images)
        output_resized = nn.functional.interpolate(output_images, size=(128, 128), mode='bilinear', align_corners=False)

        target_np = target_images.cpu().numpy().transpose(0, 2, 3, 1)
        output_np = output_resized.cpu().numpy().transpose(0, 2, 3, 1)
        input_np = input_images.cpu().numpy().transpose(0, 2, 3, 1)

        for i in range(len(output_np)):
            psnr = calculate_psnr(target_np[i], output_np[i])
            ssim_val = calculate_ssim(target_np[i], output_np[i])
            psnr_values.append(psnr)
            ssim_values.append(ssim_val)

            if i == 0:
                fig, ax = plt.subplots(1, 3, figsize=(12, 4))
                ax[0].imshow(input_np[i] * 0.5 + 0.5)
                ax[0].set_title("Low-Res Input")
                ax[1].imshow(target_np[i] * 0.5 + 0.5)
                ax[1].set_title("High-Res Target")
                ax[2].imshow(output_np[i] * 0.5 + 0.5)
                ax[2].set_title("Model Output")
                for a in ax: a.axis('off')
                plt.tight_layout()
                plt.savefig("outputs/sample_output.png")
                plt.show()

        break

print(f"Average PSNR: {np.mean(psnr_values):.2f} dB")
print(f"Average SSIM: {np.mean(ssim_values):.4f}")"""))

# Create notebook object
notebook = nbf.new_notebook(cells=cells)

# Save path
output_path = "/mnt/data/SURNet-CIFAR.ipynb"

# Write notebook
with open(output_path, "w", encoding="utf-8") as f:
    f.write(nbf.writes(notebook))

output_path
